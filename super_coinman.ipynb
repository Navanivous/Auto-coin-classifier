{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi #sometimes throws errors and has to be rerun for some reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already downloaded\n"
     ]
    }
   ],
   "source": [
    "api = KaggleApi()\n",
    "folder_path = 'Dataset'\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "    api.dataset_download_files('wanderdust/coin-images', path=folder_path, unzip=True)\n",
    "else:\n",
    "    print('Dataset already downloaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 211\n",
    "input_size = 164"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Dataset/cat_to_name.json','r') as f:\n",
    "    coin_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = {'train':[],'validation':[],'test':[]}\n",
    "labels = {'train':[],'validation':[],'test':[]}\n",
    "paths = {'train':'Dataset/coins/data/train',\n",
    "         'validation':'Dataset/coins/data/validation/',\n",
    "         'test': 'Dataset/coins/data/test/'\n",
    "         }\n",
    "for k in ['train', 'validation', 'test']:\n",
    "    for parent_file_name in os.listdir(paths[k]):\n",
    "        for file_name in os.listdir(os.path.join(paths[k],parent_file_name)):\n",
    "            if file_name.endswith(('.jpg','.png','.jpeg')):\n",
    "                image_paths[k].append(os.path.join(paths[k],parent_file_name,file_name))\n",
    "                labels[k].append(parent_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocessing(image_path, label,num_classes,augment = False):\n",
    "    \n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, np.float32) \n",
    "    image = tf.image.resize(image, [input_size, input_size])\n",
    "    label = tf.one_hot(int(label),num_classes)\n",
    "    \n",
    "    if augment:\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = tf.image.random_flip_up_down(image)\n",
    "        image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "        image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "        image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n",
    "          \n",
    "    return image, label  \n",
    "\n",
    "dataset = {}\n",
    "\n",
    "\n",
    "for k in image_paths:\n",
    "\n",
    "    image_list = image_paths[k]\n",
    "    label_list = labels[k]\n",
    "    \n",
    "    \n",
    "\n",
    "    tf_dataset = tf.data.Dataset.from_tensor_slices((image_list, label_list))\n",
    "    \n",
    "    tf_dataset = tf_dataset.map(lambda image_path, label: image_preprocessing(image_path, label, num_classes), \n",
    "                                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    if k == 'train':  \n",
    "        \n",
    "        tf_augmented_dataset = tf.data.Dataset.from_tensor_slices((image_list, label_list))\n",
    "        tf_augmented_dataset = tf_augmented_dataset.map(\n",
    "            lambda image_path, label: image_preprocessing(image_path, label, num_classes, augment=True),\n",
    "            num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "        )\n",
    "        tf_dataset = tf_dataset.concatenate(tf_augmented_dataset)\n",
    "\n",
    "    tf_dataset = tf_dataset.shuffle(buffer_size=1000).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    dataset[k] = tf_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "401/401 [==============================] - 83s 196ms/step - loss: 4.5637 - accuracy: 0.0996 - val_loss: 5.5369 - val_accuracy: 0.0450\n",
      "Epoch 2/64\n",
      "401/401 [==============================] - 70s 169ms/step - loss: 3.5330 - accuracy: 0.2478 - val_loss: 4.2910 - val_accuracy: 0.1896\n",
      "Epoch 3/64\n",
      "401/401 [==============================] - 70s 169ms/step - loss: 2.6844 - accuracy: 0.4082 - val_loss: 4.0905 - val_accuracy: 0.2287\n",
      "Epoch 4/64\n",
      "401/401 [==============================] - 70s 170ms/step - loss: 2.0170 - accuracy: 0.5437 - val_loss: 3.0901 - val_accuracy: 0.3578\n",
      "Epoch 5/64\n",
      "401/401 [==============================] - 70s 169ms/step - loss: 1.5581 - accuracy: 0.6401 - val_loss: 2.4658 - val_accuracy: 0.4775\n",
      "Epoch 6/64\n",
      "401/401 [==============================] - 70s 170ms/step - loss: 1.2081 - accuracy: 0.7168 - val_loss: 2.1080 - val_accuracy: 0.5344\n",
      "Epoch 7/64\n",
      "401/401 [==============================] - 71s 172ms/step - loss: 0.9386 - accuracy: 0.7768 - val_loss: 2.2346 - val_accuracy: 0.5308\n",
      "Epoch 8/64\n",
      "401/401 [==============================] - 70s 169ms/step - loss: 0.7301 - accuracy: 0.8240 - val_loss: 1.8810 - val_accuracy: 0.5960\n",
      "Epoch 9/64\n",
      "401/401 [==============================] - 70s 170ms/step - loss: 0.6040 - accuracy: 0.8519 - val_loss: 1.8419 - val_accuracy: 0.6090\n",
      "Epoch 10/64\n",
      "401/401 [==============================] - 71s 172ms/step - loss: 0.4843 - accuracy: 0.8827 - val_loss: 1.8955 - val_accuracy: 0.5995\n",
      "Epoch 11/64\n",
      "401/401 [==============================] - 74s 180ms/step - loss: 0.4041 - accuracy: 0.9003 - val_loss: 1.7782 - val_accuracy: 0.6374\n",
      "Epoch 12/64\n",
      "401/401 [==============================] - 77s 186ms/step - loss: 0.3313 - accuracy: 0.9180 - val_loss: 1.8733 - val_accuracy: 0.6564\n",
      "Epoch 13/64\n",
      "401/401 [==============================] - 74s 179ms/step - loss: 0.3005 - accuracy: 0.9242 - val_loss: 1.8503 - val_accuracy: 0.6552\n",
      "Epoch 14/64\n",
      "401/401 [==============================] - 84s 205ms/step - loss: 0.2677 - accuracy: 0.9312 - val_loss: 1.6434 - val_accuracy: 0.6884\n",
      "Epoch 15/64\n",
      "401/401 [==============================] - 72s 173ms/step - loss: 0.2270 - accuracy: 0.9432 - val_loss: 1.5140 - val_accuracy: 0.7145\n",
      "Epoch 16/64\n",
      "401/401 [==============================] - 69s 167ms/step - loss: 0.1993 - accuracy: 0.9525 - val_loss: 1.5541 - val_accuracy: 0.7062\n",
      "Epoch 17/64\n",
      "401/401 [==============================] - 69s 168ms/step - loss: 0.1872 - accuracy: 0.9529 - val_loss: 1.5515 - val_accuracy: 0.7121\n",
      "Epoch 18/64\n",
      "401/401 [==============================] - 69s 167ms/step - loss: 0.1691 - accuracy: 0.9578 - val_loss: 1.6557 - val_accuracy: 0.7002\n",
      "Epoch 19/64\n",
      "401/401 [==============================] - 69s 168ms/step - loss: 0.1489 - accuracy: 0.9627 - val_loss: 1.4944 - val_accuracy: 0.7251\n",
      "Epoch 20/64\n",
      "401/401 [==============================] - 70s 170ms/step - loss: 0.1387 - accuracy: 0.9630 - val_loss: 1.4767 - val_accuracy: 0.7382\n",
      "Epoch 21/64\n",
      "401/401 [==============================] - 69s 168ms/step - loss: 0.1252 - accuracy: 0.9670 - val_loss: 1.5010 - val_accuracy: 0.7287\n",
      "Epoch 22/64\n",
      "401/401 [==============================] - 69s 167ms/step - loss: 0.1172 - accuracy: 0.9694 - val_loss: 1.4917 - val_accuracy: 0.7346\n",
      "Epoch 23/64\n",
      "401/401 [==============================] - 69s 168ms/step - loss: 0.1124 - accuracy: 0.9706 - val_loss: 1.4774 - val_accuracy: 0.7322\n",
      "Epoch 24/64\n",
      "401/401 [==============================] - 69s 168ms/step - loss: 0.1046 - accuracy: 0.9702 - val_loss: 1.4497 - val_accuracy: 0.7464\n",
      "Epoch 25/64\n",
      "401/401 [==============================] - 69s 168ms/step - loss: 0.0916 - accuracy: 0.9745 - val_loss: 1.5010 - val_accuracy: 0.7358\n",
      "Epoch 26/64\n",
      "401/401 [==============================] - 69s 167ms/step - loss: 0.0890 - accuracy: 0.9743 - val_loss: 1.5637 - val_accuracy: 0.7405\n",
      "Epoch 27/64\n",
      "401/401 [==============================] - 69s 167ms/step - loss: 0.0850 - accuracy: 0.9754 - val_loss: 1.4985 - val_accuracy: 0.7358\n",
      "Epoch 28/64\n",
      "401/401 [==============================] - 69s 168ms/step - loss: 0.0784 - accuracy: 0.9769 - val_loss: 1.4721 - val_accuracy: 0.7488\n",
      "Epoch 29/64\n",
      "401/401 [==============================] - 69s 167ms/step - loss: 0.0734 - accuracy: 0.9777 - val_loss: 1.4333 - val_accuracy: 0.7595\n",
      "Epoch 30/64\n",
      "401/401 [==============================] - 69s 168ms/step - loss: 0.0747 - accuracy: 0.9781 - val_loss: 1.5111 - val_accuracy: 0.7334\n",
      "Epoch 31/64\n",
      "401/401 [==============================] - 69s 167ms/step - loss: 0.0735 - accuracy: 0.9764 - val_loss: 1.5125 - val_accuracy: 0.7393\n",
      "Epoch 32/64\n",
      "401/401 [==============================] - 69s 167ms/step - loss: 0.0682 - accuracy: 0.9793 - val_loss: 1.4576 - val_accuracy: 0.7299\n",
      "Epoch 33/64\n",
      "401/401 [==============================] - 69s 167ms/step - loss: 0.0680 - accuracy: 0.9778 - val_loss: 1.4962 - val_accuracy: 0.7441\n",
      "Epoch 34/64\n",
      "401/401 [==============================] - 69s 167ms/step - loss: 0.0604 - accuracy: 0.9800 - val_loss: 1.4801 - val_accuracy: 0.7464\n",
      "Epoch 35/64\n",
      "401/401 [==============================] - 69s 167ms/step - loss: 0.0609 - accuracy: 0.9800 - val_loss: 1.4666 - val_accuracy: 0.7441\n",
      "Epoch 36/64\n",
      "401/401 [==============================] - 69s 167ms/step - loss: 0.0563 - accuracy: 0.9811 - val_loss: 1.4720 - val_accuracy: 0.7417\n",
      "Epoch 37/64\n",
      "401/401 [==============================] - 69s 168ms/step - loss: 0.0540 - accuracy: 0.9804 - val_loss: 1.5064 - val_accuracy: 0.7464\n",
      "Epoch 38/64\n",
      "401/401 [==============================] - 69s 168ms/step - loss: 0.0531 - accuracy: 0.9799 - val_loss: 1.4470 - val_accuracy: 0.7488\n",
      "Epoch 39/64\n",
      "401/401 [==============================] - 71s 172ms/step - loss: 0.0490 - accuracy: 0.9803 - val_loss: 1.4398 - val_accuracy: 0.7512\n",
      "Epoch 40/64\n",
      "401/401 [==============================] - 70s 170ms/step - loss: 0.0503 - accuracy: 0.9807 - val_loss: 1.5815 - val_accuracy: 0.7370\n",
      "Epoch 41/64\n",
      "401/401 [==============================] - 69s 168ms/step - loss: 0.0493 - accuracy: 0.9818 - val_loss: 1.4647 - val_accuracy: 0.7559\n",
      "Epoch 42/64\n",
      "401/401 [==============================] - 69s 168ms/step - loss: 0.0477 - accuracy: 0.9816 - val_loss: 1.4679 - val_accuracy: 0.7607\n",
      "Epoch 43/64\n",
      "401/401 [==============================] - 69s 168ms/step - loss: 0.0480 - accuracy: 0.9813 - val_loss: 1.4588 - val_accuracy: 0.7476\n",
      "Epoch 44/64\n",
      "401/401 [==============================] - 70s 170ms/step - loss: 0.0447 - accuracy: 0.9819 - val_loss: 1.5724 - val_accuracy: 0.7453\n",
      "Epoch 45/64\n",
      "401/401 [==============================] - 71s 171ms/step - loss: 0.0429 - accuracy: 0.9818 - val_loss: 1.4721 - val_accuracy: 0.7488\n",
      "Epoch 46/64\n",
      "401/401 [==============================] - 70s 170ms/step - loss: 0.0420 - accuracy: 0.9830 - val_loss: 1.4863 - val_accuracy: 0.7536\n",
      "Epoch 47/64\n",
      "401/401 [==============================] - 70s 169ms/step - loss: 0.0408 - accuracy: 0.9825 - val_loss: 1.4648 - val_accuracy: 0.7559\n",
      "Epoch 48/64\n",
      "401/401 [==============================] - 69s 168ms/step - loss: 0.0419 - accuracy: 0.9819 - val_loss: 1.4520 - val_accuracy: 0.7464\n",
      "Epoch 49/64\n",
      "401/401 [==============================] - 69s 169ms/step - loss: 0.0448 - accuracy: 0.9814 - val_loss: 1.5609 - val_accuracy: 0.7393\n",
      "Epoch 50/64\n",
      "401/401 [==============================] - 69s 168ms/step - loss: 0.0399 - accuracy: 0.9830 - val_loss: 1.4919 - val_accuracy: 0.7441\n",
      "Epoch 51/64\n",
      "401/401 [==============================] - 69s 168ms/step - loss: 0.0384 - accuracy: 0.9832 - val_loss: 1.5671 - val_accuracy: 0.7405\n",
      "Epoch 52/64\n",
      "401/401 [==============================] - 69s 168ms/step - loss: 0.0386 - accuracy: 0.9828 - val_loss: 1.4994 - val_accuracy: 0.7559\n",
      "Epoch 53/64\n",
      "401/401 [==============================] - 70s 169ms/step - loss: 0.0405 - accuracy: 0.9822 - val_loss: 1.5028 - val_accuracy: 0.7512\n",
      "Epoch 54/64\n",
      "401/401 [==============================] - 69s 168ms/step - loss: 0.0393 - accuracy: 0.9821 - val_loss: 1.4903 - val_accuracy: 0.7559\n",
      "Epoch 55/64\n",
      "401/401 [==============================] - 70s 169ms/step - loss: 0.0364 - accuracy: 0.9832 - val_loss: 1.4746 - val_accuracy: 0.7500\n",
      "Epoch 56/64\n",
      "401/401 [==============================] - 70s 169ms/step - loss: 0.0368 - accuracy: 0.9823 - val_loss: 1.4925 - val_accuracy: 0.7500\n",
      "Epoch 57/64\n",
      "401/401 [==============================] - 69s 168ms/step - loss: 0.0369 - accuracy: 0.9826 - val_loss: 1.5017 - val_accuracy: 0.7595\n",
      "Epoch 58/64\n",
      "401/401 [==============================] - 69s 168ms/step - loss: 0.0375 - accuracy: 0.9828 - val_loss: 1.5089 - val_accuracy: 0.7476\n",
      "Epoch 59/64\n",
      "401/401 [==============================] - 70s 169ms/step - loss: 0.0356 - accuracy: 0.9831 - val_loss: 1.4771 - val_accuracy: 0.7618\n",
      "Epoch 60/64\n",
      "401/401 [==============================] - 69s 168ms/step - loss: 0.0345 - accuracy: 0.9828 - val_loss: 1.4651 - val_accuracy: 0.7571\n",
      "Epoch 61/64\n",
      "401/401 [==============================] - 70s 169ms/step - loss: 0.0334 - accuracy: 0.9840 - val_loss: 1.4497 - val_accuracy: 0.7630\n",
      "Epoch 62/64\n",
      "401/401 [==============================] - 70s 169ms/step - loss: 0.0327 - accuracy: 0.9832 - val_loss: 1.4484 - val_accuracy: 0.7630\n",
      "Epoch 63/64\n",
      "401/401 [==============================] - 70s 169ms/step - loss: 0.0338 - accuracy: 0.9825 - val_loss: 1.4867 - val_accuracy: 0.7607\n",
      "Epoch 64/64\n",
      "401/401 [==============================] - 69s 168ms/step - loss: 0.0345 - accuracy: 0.9830 - val_loss: 1.4968 - val_accuracy: 0.7618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a017690e50>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def residual_block(x, filters, strides=1, kernel_size=(3,3)):\n",
    "  \n",
    "    shortcut = x\n",
    "\n",
    "    x = Conv2D(filters, kernel_size=(kernel_size), strides=strides, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Conv2D(filters, kernel_size=(kernel_size), strides=1, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "\n",
    "    if x.shape[-1] != shortcut.shape[-1]:\n",
    "        shortcut = Conv2D(filters, kernel_size=(1, 1), strides=strides, padding='same', use_bias=False)(shortcut)\n",
    "        shortcut = BatchNormalization(axis=-1)(shortcut)\n",
    "\n",
    "    x = Add()([x, shortcut])\n",
    "\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def build_resnet50(input_shape, num_classes):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(64, kernel_size=(7, 7), strides=2, padding='same', use_bias=False)(input_layer)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=2, padding='same')(x)\n",
    "    \n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "\n",
    "    for _ in range(3):\n",
    "        x = residual_block(x, 64)\n",
    "\n",
    "\n",
    "    x = residual_block(x, 128, strides=2)  \n",
    "    for _ in range(3):\n",
    "        x = residual_block(x, 128)\n",
    "\n",
    "\n",
    "    x = residual_block(x, 256, strides=2)  \n",
    "    for _ in range(5):\n",
    "        x = residual_block(x, 256)\n",
    "\n",
    "  \n",
    "    x = residual_block(x, 512, strides=2)  \n",
    "    for _ in range(2):\n",
    "        x = residual_block(x, 512)\n",
    "\n",
    "  \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_resnet50((input_size,input_size,3), num_classes)\n",
    "model.compile(optimizer='sgd', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model.fit(dataset['train'], validation_data=(dataset['validation']),batch_size=32,epochs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 3s 50ms/step - loss: 1.1030 - accuracy: 0.7986\n",
      "Testing results:\n",
      " Loss: 1.1029906272888184\n",
      " Accuracy: 0.7985782027244568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 36). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: coin_man\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: coin_man\\assets\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(dataset['test'])\n",
    "print(f'Testing results:\\n Loss: {loss}\\n Accuracy: {accuracy}')\n",
    "model.save('coin_man')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
